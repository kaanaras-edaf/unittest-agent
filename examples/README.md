# Workflow Examples

This directory contains example GitHub Actions workflows for AL projects that want to use the UnitTest-Agent.

## Files Overview

### For AL Project Repositories

Copy these workflows to your AL project's `.github/workflows/` directory:

#### `target-project-workflow.yml`
- **Purpose**: Complete test generation and execution workflow
- **Triggers**: Push to main/develop branches and pull requests
- **Features**: 
  - Generates unit tests using UnitTest-Agent
  - Runs generated tests
  - Uploads test results as artifacts
  - Comments on PRs with test summary

#### `pr-workflow.yml`
- **Purpose**: Focused PR workflow for changed files only
- **Triggers**: Pull request events (opened, synchronized, reopened)
- **Features**:
  - Detects changed AL files
  - Generates tests only for modified code
  - Creates PR comments with test results
  - Uploads generated tests as artifacts

### Reference Examples

#### `sample-workflow.yml`
- Basic example showing minimal UnitTest-Agent usage
- Good starting point for simple integrations

#### `usage-example.yml`
- Comprehensive example with advanced configuration
- Shows all available input parameters

## Setup Instructions

1. **Choose a workflow**: Select either `target-project-workflow.yml` (recommended) or `pr-workflow.yml`
2. **Copy to your project**: Place the chosen file in your AL project's `.github/workflows/` directory
3. **Add secrets**: Add `OPENAI_API_KEY` to your repository secrets (Settings → Secrets and variables → Actions)
4. **Customize paths**: Adjust `docs-path` and `code-path` if your project structure differs
5. **Test**: Create a PR or push to trigger the workflow

## Required Repository Secrets

Add these secrets to your AL project repository:

| Secret | Description | Required |
|--------|-------------|----------|
| `OPENAI_API_KEY` | OpenAI API key for test generation | Yes |
| `GITHUB_TOKEN` | Automatically provided by GitHub | No (automatic) |

## Input Parameters

All workflows support these input parameters:

| Parameter | Description | Default | Required |
|-----------|-------------|---------|----------|
| `openai-api-key` | OpenAI API key | - | Yes |
| `docs-path` | Glob pattern for documentation | `./*/md/*.md,./md/*.md` | No |
| `code-path` | Glob pattern for AL files | `./*/*.al` | No |
| `output-path` | Test output directory | `./tests` | No |
| `model` | OpenAI model to use | `gpt-4o` | No |

## Expected Project Structure

Your AL project should follow this structure:

```
YourALProject/
├── .github/workflows/
│   └── [copied workflow].yml
├── Module1/
│   ├── md/
│   │   └── feature.md
│   └── *.al
├── Module2/
│   ├── md/
│   │   └── feature.md
│   └── *.al
├── md/
│   └── architecture.md
└── tests/ (generated by UnitTest-Agent)
```

## Troubleshooting

### Common Issues

1. **"Action not found"**: Ensure you're using `kaanaras-edaf/unittest-agent@v1` (not `al-test-generator`)
2. **"API key missing"**: Add `OPENAI_API_KEY` to repository secrets
3. **"No AL files found"**: Check your `code-path` glob pattern matches your file structure
4. **"No documentation found"**: Verify `docs-path` matches your documentation location

### Debug Mode

Add `DEBUG: "true"` to the workflow inputs for detailed logging:

```yaml
- name: Generate Unit Tests
  uses: kaanaras-edaf/unittest-agent@v1
  with:
    openai-api-key: ${{ secrets.OPENAI_API_KEY }}
    DEBUG: "true"  # Enable debug output
```

## Support

For issues with the UnitTest-Agent itself, visit: https://github.com/kaanaras-edaf/unittest-agent/issues